{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "74aa6614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e84407",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "id": "b4d90941",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "import torch\n",
    "\n",
    "class AddTrainValTestMask(object):\n",
    "    r\"\"\"Adds a node-level random split via :obj:`train_mask`, :obj:`val_mask`\n",
    "    and :obj:`test_mask` attributes to the :obj:`data` object.\n",
    "\n",
    "    Args:\n",
    "        split (string): The type of dataset split (:obj:`\"train_rest\"`,\n",
    "            :obj:`\"test_rest\"`, :obj:`\"random\"`).\n",
    "            If set to :obj:`\"train_rest\"`, all nodes except those in the\n",
    "            validation and test sets will be used for training (as in the\n",
    "            `\"FastGCN: Fast Learning with Graph Convolutional Networks via\n",
    "            Importance Sampling\" <https://arxiv.org/abs/1801.10247>`_ paper).\n",
    "            If set to :obj:`\"test_rest\"`, all nodes except those in the\n",
    "            training and validation sets will be used for test (as in the\n",
    "            `\"Pitfalls of Graph Neural Network Evaluation\"\n",
    "            <https://arxiv.org/abs/1811.05868>`_ paper).\n",
    "            If set to :obj:`\"random\"`, train, validation, and test sets will be\n",
    "            randomly generated, according to :obj:`num_train_per_class`,\n",
    "            :obj:`num_val` and :obj:`num_test` (as in the `\"Semi-supervised\n",
    "            Classification with Graph Convolutional Networks\"\n",
    "            <https://arxiv.org/abs/1609.02907>`_ paper).\n",
    "        num_splits (int, optional): The number of splits to add. If bigger\n",
    "            than :obj:`1`, the shape of masks will be\n",
    "            :obj:`[num_nodes, num_splits]`, and :obj:`[num_nodes]` otherwise.\n",
    "            (default: :obj:`1`)\n",
    "        num_train_per_class (int, optional): The number of training samples\n",
    "            per class in case of :obj:`\"test_rest\"` and :obj:`\"random\"` split.\n",
    "            (default: :obj:`20`)\n",
    "        num_val (int or float, optional): The number of validation samples.\n",
    "            If float, it represents the ratio of samples to include in the\n",
    "            validation set. (default: :obj:`500`)\n",
    "        num_test (int or float, optional): The number of test samples in case\n",
    "            of :obj:`\"train_rest\"` and :obj:`\"random\"` split. If float, it\n",
    "            represents the ratio of samples to include in the test set.\n",
    "            (default: :obj:`1000`)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        split: str,\n",
    "        num_splits: int = 1,\n",
    "        num_train_per_class: int = 20,\n",
    "        num_val: Union[int, float] = 500,\n",
    "        num_test: Union[int, float] = 1000,\n",
    "    ):\n",
    "        assert split in ['train_rest', 'test_rest', 'random']\n",
    "        self.split = split\n",
    "        self.num_splits = num_splits\n",
    "        self.num_train_per_class = num_train_per_class\n",
    "        self.num_val = num_val\n",
    "        self.num_test = num_test\n",
    "\n",
    "    def __call__(self, data):\n",
    "        train_masks, val_masks, test_masks = [], [], []\n",
    "        for _ in range(self.num_splits):\n",
    "            train_mask, val_mask, test_mask = self.__sample_split__(data)\n",
    "            train_masks.append(train_mask)\n",
    "            val_masks.append(val_mask)\n",
    "            test_masks.append(test_mask)\n",
    "\n",
    "        data.train_mask = torch.stack(train_masks, dim=-1).squeeze(-1)\n",
    "        data.val_mask = torch.stack(val_masks, dim=-1).squeeze(-1)\n",
    "        data.test_mask = torch.stack(test_masks, dim=-1).squeeze(-1)\n",
    "\n",
    "        return data\n",
    "\n",
    "    def __sample_split__(self, data):\n",
    "        train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "        val_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "        test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "\n",
    "        if isinstance(self.num_val, float):\n",
    "            num_val = round(data.num_nodes * self.num_val)\n",
    "        else:\n",
    "            num_val = self.num_val\n",
    "\n",
    "        if isinstance(self.num_test, float):\n",
    "            num_test = round(data.num_nodes * self.num_test)\n",
    "        else:\n",
    "            num_test = self.num_test\n",
    "\n",
    "        if self.split == 'train_rest':\n",
    "            perm = torch.randperm(data.num_nodes)\n",
    "            val_mask[perm[:num_val]] = True\n",
    "            test_mask[perm[num_val:num_val + num_test]] = True\n",
    "            train_mask[perm[num_val + num_test:]] = True\n",
    "\n",
    "        else:\n",
    "            num_classes = int(data.y.max().item()) + 1\n",
    "            for c in range(num_classes):\n",
    "                idx = (data.y == c).nonzero(as_tuple=False).view(-1)\n",
    "                idx = idx[torch.randperm(idx.size(0))]\n",
    "                idx = idx[:self.num_train_per_class]\n",
    "                train_mask[idx] = True\n",
    "\n",
    "            remaining = (~train_mask).nonzero(as_tuple=False).view(-1)\n",
    "            remaining = remaining[torch.randperm(remaining.size(0))]\n",
    "\n",
    "            val_mask[remaining[:num_val]] = True\n",
    "\n",
    "            if self.split == 'test_rest':\n",
    "                test_mask[remaining[num_val:]] = True\n",
    "            elif self.split == 'random':\n",
    "                test_mask[remaining[num_val:num_val + num_test]] = True\n",
    "\n",
    "        return train_mask, val_mask, test_mask\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}(split={})'.format(self.__class__.__name__, self.split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "id": "faff5f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform\n",
    "transform = transforms.Compose([AddTrainValTestMask('train_rest', num_val=500,\n",
    "                                                            num_test=500)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "id": "effe0a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "уникальных пользователей: 7126\n",
      "размерность фичи: torch.Size([7126, 128])\n",
      "количество взаимосвязей : 77774\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Twitch\n",
    "# download\n",
    "os.chdir('C:/Users/rustem.kamilyanov/trainee/reports/4')\n",
    "data1 = Twitch(root='.', name='EN', transform=transform)\n",
    "\n",
    "################\n",
    "features = data1[0].x\n",
    "edges = data1[0].edge_index\n",
    "targets = data1[0].y\n",
    "################\n",
    "\n",
    "################\n",
    "train_mask = np.random.choice([0, 1], size=len(features), p=[0.2, 0.8])\n",
    "test_mask = np.ones_like(train_mask) - train_mask\n",
    "#\n",
    "data = Data(x=features, \n",
    "            edge_index=edges,\n",
    "            y=targets,\n",
    "            train_mask=train_mask,\n",
    "            test_mask=test_mask)\n",
    "#################\n",
    "\n",
    "# принты\n",
    "users = np.unique([x for y in data.edge_index.t().tolist() for x in y])\n",
    "print(f'уникальных пользователей: {len(users)}')\n",
    "print(f'размерность фичи: {features.shape}')\n",
    "print(f'количество взаимосвязей : {len(edges.t())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "id": "445a2332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[7126, 128], edge_index=[2, 77774], y=[7126], train_mask=[7126], val_mask=[7126], test_mask=[7126])"
      ]
     },
     "execution_count": 717,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc79689",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "id": "bec4eb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch_geometric.nn import GCNConv\n",
    "embedding_size = 64\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self):\n",
    "        # Init parent\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(42)\n",
    "\n",
    "        # GCN layers\n",
    "        self.initial_conv = GCNConv(data.num_node_features, embedding_size)\n",
    "        self.conv1 = GCNConv(embedding_size, embedding_size)\n",
    "        self.conv2 = GCNConv(embedding_size, embedding_size)\n",
    "        self.conv3 = GCNConv(embedding_size, embedding_size)\n",
    "        \n",
    "        # softmax layer\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        # Output layer\n",
    "        self.linear = nn.Linear(embedding_size, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        # First Conv layer\n",
    "        x = self.initial_conv(x, edge_index)\n",
    "        x = torch.tanh(x)\n",
    "\n",
    "        # Other Conv layers\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = torch.tanh(x)\n",
    "          \n",
    "        # Global Pooling (stack different aggregations)\n",
    "        # hidden = torch.cat([gmp(hidden, batch_index), \n",
    "        #                   gap(hidden, batch_index)], dim=1)\n",
    "\n",
    "        # Apply a final (linear) classifier and sigmoid\n",
    "        out = self.linear(x)\n",
    "        out = self.sigmoid(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "id": "931a0283",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-718-0b3849942089>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mout_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         out_labels = torch.tensor([1.0 if x >= thr else 0 for x in out_probs], \n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-682-2126baf1a2cc>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;31m# First Conv layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataset.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attribute_name)\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# params\n",
    "model = GCN()\n",
    "lr = 0.01\n",
    "loss_func = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# model train\n",
    "model.train()\n",
    "\n",
    "mlflow.set_tracking_uri('http://localhost:5000')\n",
    "mlflow.set_experiment('gnn')\n",
    "with mlflow.start_run():\n",
    "    \n",
    "    for epoch in range(10):\n",
    "        optimizer.zero_grad()\n",
    "        out_probs = model(data1)\n",
    "         \n",
    "        out_labels = torch.tensor([1.0 if x >= thr else 0 for x in out_probs], \n",
    "                                  requires_grad=True)\n",
    "        true_labels = data1.y.to(torch.float32)\n",
    "\n",
    "        loss = loss_func(out_labels[data.train_mask], true_labels[data.train_mask])\n",
    "        #loss = loss_func(out_labels, true_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        mlflow.log_metric(key='train_loss_history', \n",
    "                          value=loss.item(), \n",
    "                         step=epoch)\n",
    "    \n",
    "    mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
