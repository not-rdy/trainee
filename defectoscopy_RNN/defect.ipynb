{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import load_npz\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_signal_path = 'C:/Users/rustem.kamilyanov/defectoscopy2/train/signal'\n",
    "train_markup_path = 'C:/Users/rustem.kamilyanov/defectoscopy2/train/markup'\n",
    "\n",
    "train_names = os.listdir(train_signal_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = []\n",
    "l = []\n",
    "\n",
    "# train signals/labels\n",
    "for name in train_names:\n",
    "    temp_s = load_npz(train_signal_path + '/' + name).toarray()\n",
    "    s.append(temp_s)\n",
    "    \n",
    "    temp_l = load_npz(train_markup_path + '/' + name).toarray()\n",
    "    l.append(temp_l)\n",
    "    \n",
    "signals_train = np.concatenate([s[i] for i in range(len(s))])\n",
    "labels_train = np.concatenate([l[i].reshape(-1) for i in range(len(l))])\n",
    "\n",
    "\n",
    "idx = np.random.choice(int(signals_train.shape[0]), int(5e+3), replace=False)\n",
    "signals_train = signals_train[idx, :]\n",
    "\n",
    "labels_train = labels_train.reshape(-1, 1)[idx, :]\n",
    "labels_train = labels_train.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(x=pd.Series(labels_train).value_counts(normalize=True).index, \n",
    "        height=pd.Series(labels_train).value_counts(normalize=True));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(labels_train).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE Resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "signals_train_scale = scaler.fit_transform(signals_train)\n",
    "\n",
    "k = 5\n",
    "sm = SMOTE(random_state=14, \n",
    "           k_neighbors=k, \n",
    "           sampling_strategy='not majority',\n",
    "           n_jobs=-1)\n",
    "signals_train_scale, labels_train = sm.fit_resample(signals_train_scale, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 5 artists>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAEvpJREFUeJzt3X+MHOV9x/H35fwjaVIIsKRybSc2wm3qQOWU84UIxW35lUOlPku1E1sETIR0bRRXrWhSTNs4qkOk0qqlQnIpTjC/AjGOU8qpMXXSAukvoHeAgzGuA1wMXkwF2zOEhIB7sP3j+Z5uvOz5nr1fu9e8X9JoZ5555plnT/Z+Zp6Z3WmrVqtIkvSOZndAktQaDARJEmAgSJKCgSBJAgwESVIwECRJgIEgSQoGgiQJMBAkSWFWszvQiJdeeqn67LPPNrsbkjSjdHR0VIBTx6o3owLh2WefZfny5c3uhiTNKNVqNetI2iEjSRJgIEiSgoEgSQIMBElSMBAkSUB+IHQBB4CngY111l8JPAk8Dvwz8IHCuvXAUzGtL5SfBeyNNq8H2hrpuCRpcuUEQjuwBbgIWAqsi9eix4AO4JeBncCfR/nJwBeBjwCdMX9SrLsB6AGWxNQ13jchSZq4nEDoJB3FDwBHge1Ad02d+4HXYv4hYEHMfxz4DjAIHIn5LmAecALwIFAFbgNWjfdNSJImLicQ5gOHCsvlKBvNFcC9Y2w7P+Zz25QkTbGcbyrXG9uvjlL3U6Sho18dY9tG2uyJiVKpNHovx/CXex8c97ZT4Q/O/GizuzAlWunvnPM3bqX+gv8upstM+7cxXf8ucs4QysDCwvIC4HCdeucDfwysBN4YY9syI8NKx2sTYCspZDoqlUpGdyVJ45ETCH2ki76LgTnAWqC3ps6HgRtJYfBioXw3cCHpQvJJMb8beAF4FTibdLZwGXDPeN+EJGnicoaMhoANpA/ydmAbsA/YDPSTwuEvgPcA34htniOFwyDwJVKoENsMxvxngFuAd5GuOQxfd5AkNUHur53uiqloU2H+/ONsuy2mWv3AGZn7lyRNMb+pLEkCDARJUjAQJEmAgSBJCgaCJAkwECRJwUCQJAEGgiQpGAiSJMBAkCQFA0GSBBgIkqRgIEiSAANBkhQMBEkSYCBIkoKBIEkC8gOhCzgAPA1srLN+BfAo6XGbqwvlvw7sKUyvA6ti3S3ADwrrljXWdUnSZMp5hGY7sAW4ACiTno/cCzxZqPMccDnwuZpt72fkg/5kUqB8u7D+88DORjstSZp8OYHQSfogH4jl7UA3xwbCwXh96zjtrAbuBV5rrIuSpOmQM2Q0HzhUWC5HWaPWAl+vKfsy8DhwHTB3HG1KkiZJTiC01SmrNrifecCZwO5C2dXAB4HlpOGkq0bZtgfoB/pLpVKDu5Uk5coJhDKwsLC8ADjc4H4+AdwN/G+h7AVSsLwB3EwamqpnK9ABdFQqlQZ3K0nKlRMIfcASYDEwhzT009vgftbx9uGiefHaRrrz6IkG25QkTaKcQBgCNpCGe/YDO4B9wGZgZdRZTjqTWAPcGOuHLSKdYXy3pt07gL0xlYBrxvMGJEmTI+cuI4BdMRVtKsz3kYaS6jlI/YvQ52buW5I0DfymsiQJMBAkScFAkCQBBoIkKRgIkiTAQJAkBQNBkgQYCJKkYCBIkgADQZIUDARJEmAgSJKCgSBJAgwESVIwECRJgIEgSQoGgiQJyA+ELuAA8DSwsc76FcCjpMdtrq5Z9yawJ6bis5gXAw8DTwF3kZ7XLElqkpxAaAe2ABcBS4F18Vr0HHA5cGed7X8CLItpZaH8WuA6YAlwBLiigX5LkiZZTiB0ks4MBoCjwHagu6bOQeBx4K3M/baRnqm8M5ZvBVZlbitJmgI5gTAfOFRYLkdZrncC/cBDjHzonwK8TBpiGqvNnti+v1QqNbBbSVIjZmXUaatTVm1gH+8HDgOnAfcBe4EfNtDm1pioVCqN7FeS1ICcM4QysLCwvID0AZ9ruO4A8ADwYaACvJeRQGq0TUnSJMsJhD7Shd/FpDuB1nLs3ULHcxIwN+ZLwDnAk6SzgfsZuSNpPXBPZpuSpCmQEwhDwAZgN7Af2AHsAzYzctfQctKZxBrgxlgP8Euk8f/vkQLgz0iBAHAVcCXpgvUpwE0TeyuSpInIuYYAsCumok2F+T7SsE+t/wDOHKXNAdIdTJKkFuA3lSVJgIEgSQoGgiQJMBAkScFAkCQBBoIkKRgIkiTAQJAkBQNBkgQYCJKkYCBIkgADQZIUDARJEmAgSJKCgSBJAgwESVIwECRJQH4gdAEHSI+73Fhn/QrgUdLjNlcXypcBD5Ieqfk48MnCuluAHwB7YlrWQL8lSZMs5xGa7cAW4ALSc5P7gF5Gno0M8BxwOfC5mm1fAy4DngJ+HniE9Gzml2P954Gd4+u6JGky5QRCJ+nMYCCWtwPdHBsIB+P1rZptv1+YPwy8CJzKSCBIklpEzpDRfOBQYbkcZY3qBOYAzxTKvkwaSroOmDvKdj1AP9BfKpXGsVtJUo6cQGirU1ZtcD/zgNuBTzNyFnE18EFgOXAycNUo224FOoCOSqXS4G4lSblyAqEMLCwsLyAN/+Q6AfgW8CfAQ4XyF0jB8gZwM+kMQpLUJDmB0AcsARaThnzWki4q55gD3A3cBnyjZt28eG0DVgFPZLYpSZoCOYEwBGwg3R20H9hBuo10M7Ay6iwnnUmsAW6M9QCfIN2Sejlvv730DmBvTCXgmgm9E0nShOTcZQSwK6aiTYX5PtJQUq2vxVTPuZn7liRNA7+pLEkCDARJUjAQJEmAgSBJCgaCJAkwECRJwUCQJAEGgiQpGAiSJMBAkCQFA0GSBBgIkqRgIEiSAANBkhQMBEkSYCBIkoKBIEkC8gOhCzgAPA1srLN+BfAo6XGbq2vWrQeeiml9ofws0uMznwauJz1bWZLUJDmB0A5sAS4ClgLr4rXoOdJzk++sKT8Z+CLwEaAz5k+KdTcAPcCSmLoa7r0kadLkBEIn6Sh+ADgKbAe6a+ocBB4H3qop/zjwHWAQOBLzXcA84ATgQaAK3AasGs8bkCRNjpxAmA8cKiyXoyzHaNvOj/mcNnuAfqC/VCpl7laS1KhZGXXqje1XM9sfbdtG2twaE5VKJXe/kqQG5ZwhlIGFheUFwOHM9kfbthzz42lTkjQFcgKhj3TRdzEwB1gL9Ga2vxu4kHQh+aSY3w28ALwKnE06W7gMuKeRjkuSJldOIAwBG0gf5PuBHcA+YDOwMuosJx31rwFujPWQLiZ/iRQqfbHNYKz7DPBV0gXrZ4B7J/ZWJEkTkXMNAWBXTEWbCvN9HDsEVLQtplr9wBmZ+5ckTTG/qSxJAgwESVIwECRJgIEgSQoGgiQJMBAkScFAkCQBBoIkKRgIkiTAQJAkBQNBkgQYCJKkYCBIkgADQZIUDARJEmAgSJJCbiB0AQdITzfbWGf9XOCuWP8wsCjKLwH2FKa3gGWx7oFoc3jd+xrtvCRp8uQEQjuwBbgIWAqsi9eiK4AjwOnAdcC1UX4HKQCWAZcCB0kf/sMuKax/cTxvQJI0OXICoZN05D8AHAW2A901dbqBW2N+J3Ae0FZTZx3w9XH3VJI0pXICYT5wqLBcjrLR6gwBrwCn1NT5JG8PhJtJZwxf4O0BIkmaRjmBUO+DutpgnY8ArwFPFMouAc4EPhbTpaPsvwfoB/pLpVJGdyVJ45ETCGVgYWF5AXD4OHVmAScCg4X1a3n72cHz8foqcCdpaKqerUAH0FGpVDK6K0kaj5xA6AOWAIuBOaQP996aOr3A+phfDdzHyBnCO4A1pGsPw2YBw4f7s4GLOfbsQZI0zWZl1BkCNgC7SXccbQP2AZtJQzm9wE3A7aSLz4Ok0Bi2gnQGMVAomxvtzY42/wn4ygTehyRpgnICAWBXTEWbCvOvk84C6nkAOLum7MfAWZn7liRNA7+pLEkCDARJUjAQJEmAgSBJCgaCJAkwECRJwUCQJAEGgiQpGAiSJMBAkCQFA0GSBBgIkqRgIEiSAANBkhQMBEkSYCBIkoKBIEkC8gOhCzhAekTmxjrr5wJ3xfqHgUVRvgj4CbAnpr8tbHMWsDe2uR5oa6jnkqRJlRMI7cAW4CJgKbAuXouuAI4ApwPXAdcW1j0DLIvpdwrlNwA9wJKYuhrvviRpsuQEQifpKH4AOApsB7pr6nQDt8b8TuA8jn/EPw84AXgQqAK3Aauyey1JmnQ5gTAfOFRYLkfZaHWGgFeAU2J5MfAY8F3gY4X65THalCRNo1kZdeod6Vcz67wAvB/4H9I1g78HPpTZ5rCemCiVShndlSSNR84ZQhlYWFheABw+Tp1ZwInAIPAGKQwAHiFdT/iFqL9gjDaHbQU6gI5KpZLRXUnSeOQEQh/pou9iYA6wFuitqdMLrI/51cB9pCP+U0kXpQFOi3YGSGcOrwJnk84WLgPuGe+bkCRNXM6Q0RCwAdhN+nDfBuwDNgP9pDC4CbiddPF5kBQaACui3hDwJukuo8FY9xngFuBdwL0xSZKaJCcQAHbFVLSpMP86sKbOdt+MqZ5+4IzM/UuSppjfVJYkAQaCJCkYCJIkwECQJAUDQZIEGAiSpGAgSJIAA0GSFAwESRJgIEiSgoEgSQIMBElSMBAkSYCBIEkKBoIkCTAQJEnBQJAkAfmB0AUcID0ic2Od9XOBu2L9w8CiKL8AeATYG6/nFrZ5INrcE9P7Guq5JGlS5TxCsx3YQvpwLwN9pOcoP1mocwVwBDid9Dzla4FPAhXgN4HDpMdl7gbmF7a7hPQoTUlSk+WcIXSSjvwHgKPAdqC7pk43cGvM7wTOA9qAx0hhALAPeCfpbEKS1GJyAmE+cKiwXObYo/zaOkPAK8ApNXV+ixQQbxTKbiYNF32BFCCSpCbJCYR6H9TVBut8iDSM9NuFskuAM4GPxXTpKPvvIQ0r9ZdKpYzuSpLGIycQysDCwvICRoaB6tWZBZwIDBbq3w1cBjxT2Ob5eH0VuJM0NFXPVqAD6KhUKhndlSSNR04g9AFLgMXAHNJF496aOr3A+phfDdxHOkN4L/At4Grg3wv1ZwHDh/uzgYuBJxrvviRpsuQEwhCwgXSH0H5gB+kC8WZgZdS5iXTN4GngSkZuTd1AuvPoCxx7e+ncaO/xKHse+MqE340kadxybjsF2BVT0abC/OvAmjrbXRNTPWdl7luSNA38prIkCTAQJEnBQJAkAQaCJCkYCJIkwECQJAUDQZIEGAiSpGAgSJIAA0GSFAwESRJgIEiSgoEgSQIMBElSMBAkSYCBIEkKBoIkCcgPhC7gAOkRmRvrrJ8L3BXrHwYWFdZdHeUHgI830KYkaRrlBEI7sAW4CFgKrIvXoiuAI6TnJ18HXBvlS4G1wIdIAfA30V5Om5KkaZQTCJ2ko/gB4CiwHeiuqdMN3BrzO4HzgLYo3w68Afwg2unMbFOSNI1yAmE+cKiwXI6y0eoMAa8Apxxn25w2JUnTaFZGnbY6ZdXMOqOV1wui2jaH9cRER0fHj6rV6oFR6k2XElCZaCNXVkd7u1NiUvo8jX5q/8Yzsc/T7Kfy7zwJ/f1ATqWcQCgDCwvLC4DDo9QpR5snAoNjbDtWm8O2xtQq+oGOZneiQTOtzzOtv2Cfp4t9nkI5Q0Z9wBJgMTCHdJG4t6ZOL7A+5lcD95GO+Huj/tzYfgnwn5ltSpKmUc4ZwhCwAdhNujtoG7AP2ExKvl7gJuB20oXiQdIHPFFvB/BktPNZ4M1YV69NSVKTtFWndyzt/4MeWmsIK8dM6/NM6y/Y5+lin6eQgSBJAvzpCklSMBDyzcSf2tgGvAg80eyOZFoI3A/sJ11T+r3mdifLO0k3SnyP1Oc/bW53srUDjwH/0OyOZDoI7AX2kK5dzgTvJX1R979I/6Y/2tzujM0hozztwPeBC0i30vaRfm7jyWZ2KsMK4EfAbcAZTe5LjnkxPQr8LPAIsIrW/ju3Ae8m/Z1nA/9GCrKHmtmpDFeSboU8Abi4yX3JcZDU35n0vYlbgX8Fvkq6m/JngJeb2qMxeIaQZ6b+1Ma/kO76mileIIUBwKuko6pW/wZ7lRQGkAJhNqN/ybJVLAB+g/RBpalxAumA7KZYPkqLhwEYCLn8qY3ptwj4MOnXc1tdO2ko40XgO7R+n/8a+EPgrWZ3pAFV4Nuks8aeJvclx2nAS8DNpKG5r5LOJFuagZAn5+c7NHneA3wT+H3gh03uS443gWWkI+9OWnt47mJScD3S7I406BzgV0i/kPxZ0tF3K5tF6u8NpAObHzMDrj0aCHlyfr5Dk2M2KQzuAP6uyX1p1MvAA6QbEFrVOcBK0pj8duBc4GvN7FCm4f9vLwJ3k4K3lZVjGj5b3EkKiJZmIOTxpzamRxtpzHU/8FdN7kuuU0l3kwC8CzifdFdJq7qadECziPTv+D7gU83sUIZ3k24yGJ6/kNa/c+6/ScPMvxjL59HaN0cAeT9dodF/vqPVfR34NdKvLZaBLzJykasVnQNcysjthQB/BOxqWo/GNo90N0k76QBrBzPnVs6Z4udIZwWQPrPuBP6xed3J9rukM905pBtSPt3c7ozN204lSYBDRpKkYCBIkgADQZIUDARJEmAgSJKCgSBJAgwESVIwECRJAPwfBVuj5kE1KggAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(x=pd.Series(labels_train).value_counts(normalize=True).index, \n",
    "        height=pd.Series(labels_train).value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0    4337\n",
       "2.0    4337\n",
       "6.0    4337\n",
       "3.0    4337\n",
       "0.0    4337\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(labels_train).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_signal_path = 'C:/Users/rustem.kamilyanov/defectoscopy2/test/signal'\n",
    "test_markup_path = 'C:/Users/rustem.kamilyanov/defectoscopy2/test/markup'\n",
    "\n",
    "test_names = os.listdir(test_signal_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = []\n",
    "l = []\n",
    "\n",
    "# test signals/labels\n",
    "for name in test_names:\n",
    "    temp_s = load_npz(test_signal_path + '/' + name).toarray()\n",
    "    s.append(temp_s)\n",
    "    \n",
    "    temp_l = load_npz(test_markup_path + '/' + name).toarray()\n",
    "    l.append(temp_l)\n",
    "    \n",
    "signals_test = np.concatenate([s[i] for i in range(len(s))])\n",
    "labels_test = np.concatenate([l[i].reshape(-1) for i in range(len(l))])\n",
    "\n",
    "idx = np.random.choice(int(signals_test.shape[0]), 1500, replace=False)\n",
    "signals_test = signals_test[idx, :]\n",
    "labels_test = labels_test.reshape(-1, 1)[idx, :]\n",
    "labels_test = labels_test.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(x=pd.Series(labels_test).value_counts(normalize=True).index, \n",
    "        height=pd.Series(labels_test).value_counts(normalize=True));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class edDataset(Dataset):\n",
    "    def __init__(self, sample, labels) -> None:\n",
    "        super(edDataset, self).__init__\n",
    "        \n",
    "        self.sam = torch.tensor(sample, dtype=torch.float)\n",
    "        self.lab = torch.tensor(labels, dtype=torch.long)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sam)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.sam[idx], self.lab[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "    \n",
    "class dlDataset(object):\n",
    "    \n",
    "    def __init__(self, signals_train, labels_train, \n",
    "                 signals_test, labels_test, batch_size, input_size) -> None:\n",
    "        \n",
    "        self.signals_train = signals_train\n",
    "        self.labels_train = labels_train\n",
    "        self.signals_test = signals_test\n",
    "        self.labels_test = labels_test\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "    \n",
    "    def get_train(self):\n",
    "        dataset = edDataset(self.signals_train, self.labels_train)\n",
    "        return DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
    "    \n",
    "    def get_test(self):\n",
    "        dataset = edDataset(self.signals_test, self.labels_test)\n",
    "        return DataLoader(dataset, batch_size=self.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def metric(model, test_loader):\n",
    "    # качество распознования классов\n",
    "    class_recognition = {'0': [], \n",
    "                        '1': None, '2': [], '3': [],\n",
    "                        '4': None, '5': [], '6': []}\n",
    "\n",
    "    for x, y in test_loader:\n",
    "        raw_predict = model(x.to(device))\n",
    "        class_probs = nn.Softmax(dim=0)(raw_predict)\n",
    "        \n",
    "        predict_classes = [clss.argmax().item() for clss in class_probs]\n",
    "        true_classes = y.tolist()\n",
    "        \n",
    "        for predict_class, true_class in zip(predict_classes, true_classes):\n",
    "            if predict_class == true_class:\n",
    "                class_recognition[str(true_class)].append(1)\n",
    "            else:\n",
    "                if predict_class != true_class:\n",
    "                    class_recognition[str(true_class)].append(0)\n",
    "        \n",
    "    out = {'0': round(sum(class_recognition['0'])/len(class_recognition['0']), 2),\n",
    "           '1': None, \n",
    "           '2': round(sum(class_recognition['2'])/len(class_recognition['2']), 2), \n",
    "           '3': round(sum(class_recognition['3'])/len(class_recognition['3']), 2),\n",
    "           '4': None, \n",
    "           '5': round(sum(class_recognition['5'])/len(class_recognition['5']), 2), \n",
    "           '6': round(sum(class_recognition['6'])/len(class_recognition['6']), 2)}\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def train_pipeline(model, optimizer, loss_func, dataloader, num_epochs, \n",
    "                   num_layers, bidirectional):\n",
    "    loss_history_epoch = []\n",
    "    \n",
    "    metric_history_epoch = []\n",
    "    a_class = []\n",
    "    b_class = []\n",
    "    c_class = []\n",
    "    d_class = []\n",
    "    e_class = []\n",
    "    f_class = []\n",
    "    g_class = []\n",
    "\n",
    "    test_loader = dataloader.get_test()\n",
    "\n",
    "    for idx_epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loader = dataloader.get_train()\n",
    "\n",
    "        loss_history_batch = []\n",
    "\n",
    "        for x, y in tqdm(train_loader, desc=f'[Epoch #{idx_epoch}]',\n",
    "                                           total=len(train_loader)):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if bidirectional:\n",
    "                model.hidden_cell = (torch.zeros(num_layers*2, 1, model.hidden_layer_size),\n",
    "                                     torch.zeros(num_layers*2, 1, model.hidden_layer_size))\n",
    "            else:\n",
    "                model.hidden_cell = (torch.zeros(num_layers, 1, model.hidden_layer_size),\n",
    "                                     torch.zeros(num_layers, 1, model.hidden_layer_size))\n",
    "\n",
    "            \n",
    "            y_hat = model(x.to(device))\n",
    "\n",
    "            loss = loss_func(y_hat, y.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_history_batch.append(loss.item())\n",
    "        \n",
    "        # Eval\n",
    "        model.eval()\n",
    "        metric_out = metric(model=model, test_loader=test_loader)\n",
    "        a = metric_out['0']\n",
    "        b = metric_out['1']\n",
    "        c = metric_out['2']\n",
    "        d = metric_out['3']\n",
    "        e = metric_out['4']\n",
    "        f = metric_out['5']\n",
    "        g = metric_out['6']\n",
    "        \n",
    "        a_class.append(a)\n",
    "        b_class.append(b)\n",
    "        c_class.append(c)\n",
    "        d_class.append(d)\n",
    "        e_class.append(e)\n",
    "        f_class.append(f)\n",
    "        g_class.append(g)\n",
    "        \n",
    "        loss_history_epoch.append(sum(loss_history_batch)/len(loss_history_batch))\n",
    "        metric_history_epoch.append(metric_out)\n",
    "        \n",
    "        if idx_epoch%1==0:\n",
    "            #print(f'[Epoch #{idx_epoch}], \\\n",
    "            #LOSS: {loss_history_epoch[idx_epoch]:.3f}, \\\n",
    "            #Class Recognition: {a, b, c, d, e, f, g}')\n",
    "            \n",
    "            clear_output(wait=True)\n",
    "            plt.figure(figsize=(15,8))\n",
    "            plt.plot(loss_history_epoch, label='LOSS', c='red')\n",
    "            plt.plot(a_class, label='Class: 0')\n",
    "            plt.plot(b_class)\n",
    "            plt.plot(c_class, label='Class: 2')\n",
    "            plt.plot(d_class, label='Class: 3')\n",
    "            plt.plot(e_class)\n",
    "            plt.plot(f_class, label='Class: 5')\n",
    "            plt.plot(g_class, label='Class: 6')\n",
    "            plt.title(f'LOSS: {loss_history_epoch[idx_epoch]:.3f} \\n \\n\\\n",
    "            class_0: {a}, \\\n",
    "            class_1: {b}, \\\n",
    "            class_2: {c}, \\\n",
    "            class_3: {d}, \\\n",
    "            class_4: {e}, \\\n",
    "            class_5: {f}, \\\n",
    "            class_6: {g} \\n  ')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "    return loss_history_epoch, metric_history_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, num_layers, bidirectional, dropout, input_size, hidden_layer_size=100, output_size=4):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        \n",
    "        if bidirectional:\n",
    "            self.hidden_cell = (torch.zeros(num_layers*2, 1, hidden_layer_size),\n",
    "                                torch.zeros(num_layers*2, 1, hidden_layer_size))\n",
    "            self.lstm_list = nn.LSTM(input_size=input_size, hidden_size=hidden_layer_size, \n",
    "                                     num_layers=num_layers, bidirectional=bidirectional, \n",
    "                                     dropout=dropout, )\n",
    "            self.linear = nn.Linear(hidden_layer_size*2, output_size)\n",
    "        else:\n",
    "            self.hidden_cell = (torch.zeros(num_layers, 1, hidden_layer_size),\n",
    "                                torch.zeros(num_layers, 1, hidden_layer_size))\n",
    "            self.lstm_list = nn.LSTM(input_size=input_size, hidden_size=hidden_layer_size, \n",
    "                                     num_layers=num_layers, bidirectional=bidirectional, \n",
    "                                     dropout=dropout)\n",
    "            self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "        \n",
    "    def forward(self, train_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm_list(train_seq.view(len(train_seq), 1, -1), \n",
    "                                                    self.hidden_cell)\n",
    "        \n",
    "        predictions = self.linear(lstm_out.view(len(train_seq), -1))\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(dataloader.get_train()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch #0]:   6%|████▎                                                              | 138/2135 [00:09<02:20, 14.19it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-070848551419>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m                                                           \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m                                                           \u001b[0mnum_layers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m                                                           bidirectional=bidirectional)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-b065a76c6b9d>\u001b[0m in \u001b[0;36mtrain_pipeline\u001b[1;34m(model, optimizer, loss_func, dataloader, num_epochs, num_layers, bidirectional)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Progs\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-fdb5201535b6>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, train_seq)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         lstm_out, self.hidden_cell = self.lstm_list(train_seq.view(len(train_seq), 1, -1), \n\u001b[1;32m---> 24\u001b[1;33m                                                     self.hidden_cell)\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Progs\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Progs\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    557\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 559\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Progs\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward_tensor\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    537\u001b[0m         \u001b[0munsorted_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 539\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Progs\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[1;34m(self, input, hx, batch_sizes, max_batch_size, sorted_indices)\u001b[0m\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m             result = _VF.lstm(input, hx, self._get_flat_weights(), self.bias, self.num_layers,\n\u001b[1;32m--> 522\u001b[1;33m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[0;32m    523\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._get_flat_weights(), self.bias,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# params\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "batch_size = 10\n",
    "lr = 2e-4\n",
    "num_epochs = 20\n",
    "n_layers = 2\n",
    "input_size_dot = 1284\n",
    "hidden_layer_size = 100\n",
    "output_size_dot = 7\n",
    "bidirectional = True\n",
    "dropout= 0.3\n",
    "\n",
    "signals_test_scale = scaler.fit_transform(signals_test)\n",
    "\n",
    "dataloader = dlDataset(batch_size=batch_size, input_size=input_size_dot,\n",
    "                       labels_test=labels_test, labels_train=labels_train, \n",
    "                       signals_test=signals_test_scale, signals_train=signals_train_scale)\n",
    "\n",
    "model_dot = LSTM(num_layers=n_layers, input_size=input_size_dot, \n",
    "             hidden_layer_size=hidden_layer_size, output_size=output_size_dot, \n",
    "             bidirectional=bidirectional, dropout=dropout)\n",
    "\n",
    "optimizer = optim.Adam(model_dot.parameters(), lr=lr)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "loss_history_epoch, metric_history_epoch = train_pipeline(model=model_dot,\n",
    "                                                          optimizer=optimizer,\n",
    "                                                          loss_func=loss_func,\n",
    "                                                          dataloader=dataloader,\n",
    "                                                          num_epochs=num_epochs,\n",
    "                                                          num_layers=n_layers,\n",
    "                                                          bidirectional=bidirectional)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
